

1. 基础名词解释

| 名词      | 解释                                                         |
| --------- | ------------------------------------------------------------ |
| producer  | 生产者，产生数据的，将数据发到指定topic。                    |
| consumer  | 消费者，消费数据的，消费指定topic的数据。                    |
| broker    | 可以理解为kafka服务端的整体，客户端只需要跟他打交道即可，不用关注其内部。 |
| topic     | 理解为消息分类或者消息组即可。                               |
| group     | 消费者组，同一个group对同一个topic的数据只会被消费一次。     |
| message   | 消息本身。组成包括offset、messageSize、data三块，就是字面的意思。 |
| partition | 消息分区，跟topic关联，一个topic可能有多个partition，分布式存储该topic的数据。对生产者和消费者无感知。partition尽可能多过消费者，不然部分消费者可能取不到数据。 |

2. consumer消费topic数据时，并不是像队列那样。具体逻辑是，consumer发送一个topic的offset，然后根据请求数收到一条或者多条数据，并更新consumer本地的offset。kafka对zk间歇性发送当前offset告诉服务端更新该group的最新offset。

   - 新版本改为提交到一个名为__consumeroffsets的topic并永远读取最新的offset，解除了对zk的依赖，相当轻量级。此外consumer还可以将offset往回移再次消费那些消费过的数据。

3. 基于上一点可得知，kafka尽可能保证不丢数据，但是没法很精确保证读取的重复。比如consumer-a提交了一个offset=100给zk，consumer-b消费到offset=110了因为某些因素导致没提交，consumer-a再消费时就可能会取到旧数据。如果要保证不重复需要做很多额外的工作，也就是说，不适合需要保证很完整的收发数据的场景。

4. kafka的数据会根据配置保存一定时间，期间内都可以被消费。如果数据量大且存的时间长，需要考虑好磁盘空间的问题。

5. kafka集群和生产者、消费者都依赖zk，包括调度和维护一些元数据，比如节点信息，比如leader/follower，比如group对topic的offset等。

6. kafka的各实例在出现故障转移争取leader时，根据zk建议，一切从简，第一个获取到node的就是leader了，具体细节zk内部处理（其实就是paxos算法）。

7. kafka的拓扑结构借用[CSDN一篇博文](https://blog.csdn.net/u010020099/article/details/82290403)的一张图，大致如下：

   ![20180902105920995](20180902105920995.png)

8. rebalance相关

   1. 触发条件
      - consumer组员发生变化
        - 组员主动离开/加入
        - 组员崩溃
      - 正则订阅topic匹配，其实类似组员主动加入
      - topic分区数变了
   2. consumer分配策略
      - round-robin
      - range
      - 支持自定义

